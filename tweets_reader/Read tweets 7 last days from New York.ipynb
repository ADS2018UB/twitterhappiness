{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'consumer_key.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-575ea6971ed2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'consumer_key.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mconsumer_key\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclosed\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'consumer_key.txt'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pymongo\n",
    "import tweepy\n",
    "\n",
    "with open('/credentials/consumer_key.txt', 'r') as f:\n",
    "    consumer_key =  f.read().strip()\n",
    "f.closed\n",
    "\n",
    "with open('/credentials/consumer_secret.txt', 'r') as f:\n",
    "    consumer_secret = f.read().strip()\n",
    "f.closed\n",
    "\n",
    "with open('/credentials/access_key.txt', 'r') as f:\n",
    "    access_key = f.read().strip()\n",
    "f.closed\n",
    "\n",
    "with open('/credentials/access_secret.txt', 'r') as f:\n",
    "     access_secret = f.read().strip()\n",
    "f.closed\n",
    "\n",
    "#Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = tweepy.API(auth)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a Standard API you can only access tweets from the last 7 days, so there is no need for a filter. However, we should store those tweets if we want to create historical data, otherwise we won't have access to them after 7 days. We can also restrict the language of the tweets, which is a good idea since our machine learning model will only work on English tweets. We can restrict the geolocation using geo_search or using coordinates inside api.search within the parameter geocode. The tweets are chosen randomly. However there are some limitiations. Only 180 queries are allowed every 15min. In 180 queries we can get approximately seven thousand tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "places = api.geo_search(query=\"New York\", granularity=\"city\")\n",
    "place_id = places[0].id\n",
    "\n",
    "tweets = api.search(q=\"place:%s\" % place_id, lang='en', count=10)\n",
    "for tweet in tweets:\n",
    "    print(tweet.text + \" | \" + tweet.place.name if tweet.place else \"Undefined place\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to get a high amount of tweets we can loop over the maximum number of queries. The following cell keeps storing tweets to the mongo db database and freezes 15 minutes every time we reach the maximum number of queries. We can break the loop whenever we feel we have enough tweets by changing the parameter K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "max_queries = 180\n",
    "count = 0\n",
    "K = 50\n",
    "\n",
    "while True:\n",
    "    for i in range(max_queries):\n",
    "        tweets = api.search(q=\"place:%s\" % place_id, lang='en', count=1000)\n",
    "            for tweet in tweets:\n",
    "                #save to mongodb\n",
    "                pass\n",
    "    count +=1\n",
    "    if count > K: break\n",
    "    time.sleep(910)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also stream tweets from New York"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** esjacobs ** : @WalshFreedom you yesterday: ‚Äúvote for republicans!‚Äù\n",
      "** Silvanita2812 ** : ‚ÄúTodos me dicen la negra, llorona...‚Äù https://t.co/FMJJNpT7xz\n",
      "** Brittnaeee ** : The city is mineüìç https://t.co/JxknCDfAfb\n",
      "** Aoiferocksitout ** : @brooklynburning Saaaaame!! ‚ù§Ô∏è‚ù§Ô∏è\n",
      "** spanishzac ** : PEOPLE OVER 75 SHOULD NOT BE ALLOWED TO VOTE!!!!! They will not be here to see the consequences of their actions!!!!\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "from tweepy import Stream,StreamListener\n",
    "\n",
    "class listener(StreamListener):\n",
    "    def __init__(self):\n",
    "        super(StreamListener, self).__init__()\n",
    "        self.num_tweets = 0\n",
    "        \n",
    "    def on_data(self, status):\n",
    "        if self.num_tweets < 5:\n",
    "            json_data=json.loads(status)\n",
    "            print (str('** '+json_data[\"user\"][\"screen_name\"])+' ** : ' + json_data[\"text\"])\n",
    "            self.num_tweets += 1\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def on_error(self, status):\n",
    "        print (status)\n",
    "        \n",
    "# Catch all tweets in New York area and print them\n",
    "twitterStream = Stream(auth, listener()) \n",
    "twitterStream.filter(locations=[-74.1781,40.5609,-73.7468,40.8866])\n",
    "print (\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
